---
title: "텐서플로우 모델을 작성하는 세가지 방법"
excerpt: "Sequential, Functional, Subclassing"

categories:
  - 딥러닝
tags:
  - Deep Learning
  - Machine Learning
  - Data Science

toc: true
toc_sticky: true

---

## Tensorflow 모델 작성법

1. Sequential
2. Functional
3. Subclassing
<br/>

### Sequential 사용법
```python

import tensorflow as tf

# build a model type 1
model = tf.keras.Sequntial()
model.add(tf.keras.layers.__layer-name__(__params__))
model.add(tf.keras.layers.__layer-name__(__params__))
model.add(tf.keras.layers.__layer-name__(__params__))

# build a model type 2
model = tf.keras.Sequential([
	tf.keras.layers.__layer-name__(__params__),
	tf.keras.layers.__layer-name__(__params__),
	tf.keras.layers.__layer-name__(__params__)
])

```
Sequential 모델은 하나의 입력 - 하나의 출력을 전제로 합니다.
<br/>

### Functional 사용법
```python

import tensorflow as tf

# params
inputs = tf.keras.Input(shape = (__input-shape__))
x = tf.keras.layers.__layer-name__(__params__)(input)
x = tf.keras.layers.__layer-name__(__params__)(x)
outputs = tf.keras.layers.__layer-name__(__params__)(x)

# build a model
model = tf.keras.Model(inputs = inputs, outputs = outputs)

```
Functional 모델은 input과 output을 정의하여 생성합니다.
다중 입출력이 가능합니다.
<br/>

### Subclassing 사용법
```python

import tensorflow as tf

class MyModel(tf.keras.Model):
	def __init__(self):
		super(MyModel, self).__init__()
		self.__mylayer__ = tf.keras.layers.__layer-name__(__params__)
		self.__mylayer__ = tf.keras.layers.__layer-name__(__params__)
		self.__mylayer__ = tf.keras.layers.__layer-name__(__params__)

	def call(self, x):
		x = self.__mylayer__(x)
		x = self.__mylayer__(x)
		x = self.__mylayer__(x)

		return x

```

## 실습 1. MNIST

MNIST 데이터는 숫자 손글씨 이미지와 0부터 9까지의 숫자로 이루어져 있습니다.<br/>
이미지를 받아서 0부터 9까지의 숫자 중 하나로 분류하는 모델을 만들어보겠습니다.<br/>
[Tensorflow, Datasets, MNIST](https://www.tensorflow.org/datasets/catalog/mnist)

**요구사항**
- Data
  - 데이터 로드
  - 데이터 정규화 (0~255 → 0~1)
  - 데이터 차원 확장 (newaxis)
- Model
  1. 필터가 32개, 커널 사이즈가 3이며 relu를 사용하는 Conv2D 레이어
  2. 필터가 64개, 커널 사이즈가 3이며 relu를 사용하는 Conv2D 레이어
  3. 1차원 변환
  4. 출력 노드가 128개이며 relu를 사용하는 fully-connected 레이어
  5. 출력값이 10개(0부터 9까지의 숫자)이며 softmax를 사용하는 fully-connected 레이어
- Train
  - 최적화 함수 adam, 손실 함수 크로스엔트로피를 사용하여 모델 컴파일
  - 모델 피팅 (학습 횟수 5회)
  - 모델 평가

Conv2D 레이어의 필터는 커널 채널의 개수를 말합니다.
커널의 사이즈란 커널 채널의 크기를 말합니다.

필터가 32개, 커널 사이즈가 3인 Conv2D 레이어란 아래 이미지와 같은 3x3 크기의 커널 채널을 32개 만들겠다는 의미입니다.

<figure style = "width : 700px" class="align-center">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/conv2dkernel.gif" alt="">
  <figcaption>https://stackoverflow.com/questions/54098364/understanding-channel-in-convolution-neural-network-cnn-input-shape-and-output</figcaption>
</figure>

이미지와 같이 커널은 한번에 커널 크기만큼의 이미지 픽셀 값을 얻으며, 이미지의 모든 값을 얻을 때까지 반복합니다.

### Sequential
```python
import tensorflow as tf
import numpy as np

# data
mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255, x_test / 255 # rescaling

x_train = x_train[..., np.newaxis]
x_test = x_test[..., np.newaxis]

# build a model (5 layers)
model = tf.keras.Sequential([
		# 1. filter(kernel channel) = 32, kernel = 3, relu, conv2d layer
    tf.keras.layers.Conv2D(32, 3, activation='relu'),
		# 2. filter = 64, kernel = 3, relu, conv2d layer
    tf.keras.layers.Conv2D(64, 3, activation='relu'),
		# 3. flatten layer
    tf.keras.layers.Flatten(),
	  # 4. output = 128 nodes, relu, fully-connected dense layer
    tf.keras.layers.Dense(128, activation='relu'),
		# 5. ouput = class (data), relu, fully-connected dense layer
    tf.keras.layers.Dense(10, activation='softmax')
])

# parameter updates method = adam, loss function = crossentropy
model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])

# adjust model
model.fit(x_train, y_train, epochs = 5)

model.evaluate(x_test, y_test, verbose = 2)
```
### Functional
```python

import tensorflow as tf
import numpy as np

# data
mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255, x_test / 255 # rescaling

x_train = x_train[..., np.newaxis]
x_test = x_test[..., np.newaxis]

# build a model (5 layers)
inputs = tf.keras.Input(shape = (28, 28, 1))
x = tf.keras.layers.Conv2D(32, 3, activation = 'relu')(inputs)
x = tf.keras.layers.Conv2D(64, 3, activation = 'relu')(x)
x = tf.keras.layers.Flatten()(x)
x = tf.keras.layers.Dense(128, activation = 'relu')(x)
outputs = tf.keras.layers.Dense(10, activation = 'softmax')(x)

model = tf.keras.Model(inputs = inputs, outputs = outputs)

# compile model
model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])

# adjust model
model.fit(x_train, y_train, epochs = 5)

model.evaluate(x_test, y_test, verbose = 2)

```
### Subclassing
```python

import tensorflow as tf
import numpy as np

# data
mnist = tf.keras.datasets.mnist
(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255, x_test / 255 # rescaling

x_train = x_train[..., np.newaxis]
x_test = x_test[..., np.newaxis]

# build a model
class MNISTModel(tf.keras.Model):
    def __init__(self):
        super(MNISTModel, self).__init__()
        self.Conv2D1 = tf.keras.layers.Conv2D(32, 3, activation = 'relu')
        self.Conv2D2 = tf.keras.layers.Conv2D(64, 3, activation = 'relu')
        self.Flatten = tf.keras.layers.Flatten()
        self.Dense1 = tf.keras.layers.Dense(128, activation = 'relu')
        self.Dense2 = tf.keras.layers.Dense(10, activation = 'softmax')

    def call(self, x):
        x = self.Conv2D1(x)
        x = self.Conv2D2(x)
        x = self.Flatten(x)
        x = self.Dense1(x)
        x = self.Dense2(x)

        return x

model = MNISTModel()

# compile model
model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])

# adjust model
model.fit(x_train, y_train, epochs = 5)

model.evaluate(x_test, y_test, verbose = 2)

```

## 실습 2. CIFAR - 100
CIFAR 데이터는 이미지와 그 이미지에 해당하는 100개의 클래스로 이루어져 있습니다.<br/>
이미지와 클래스는 다음과 같습니다.

| **Superclass** | **Classes** |
| aquatic mammals | beaver, dolphin, otter, seal, whale |
| fish | aquarium fish, flatfish, ray, shark, trout |
| flowers | orchids, poppies, roses, sunflowers, tulips |
| food containers | bottles, bowls, cans, cups, plates |
| fruit and vegetables | apples, mushrooms, oranges, pears, sweet peppers |
| household electrical devices | clock, computer keyboard, lamp, telephone, television |
| household furniture | bed, chair, couch, table, wardrobe |
| insects | bee, beetle, butterfly, caterpillar, cockroach |
| large carnivores | bear, leopard, lion, tiger, wolf |
| large man-made outdoor things | bridge, castle, house, road, skyscraper |
| large natural outdoor scenes | cloud, forest, mountain, plain, sea |
| large omnivores and herbivores | camel, cattle, chimpanzee, elephant, kangaroo |
| medium-sized mammals | fox, porcupine, possum, raccoon, skunk |
| non-insect invertebrates | crab, lobster, snail, spider, worm |
| people | baby, boy, girl, man, woman |
| reptiles | crocodile, dinosaur, lizard, snake, turtle |
| small mammals | hamster, mouse, rabbit, shrew, squirrel |
| trees | maple, oak, palm, pine, willow |
| vehicles 1 | bicycle, bus, motorcycle, pickup truck, train |
| vehicles 2 | lawn-mower, rocket, streetcar, tank, tractor |

다양한 이미지로부터 클래스를 분류하는 모델을 작성하겠습니다.
<br/>

[Tensorflow, Datasets, CIFAR-100](https://www.tensorflow.org/datasets/catalog/cifar100)

**요구사항**
- Data
  - 데이터 로드
  - 데이터 정규화 (0~255 → 0~1)
- Model
  1. 필터가 16개, 커널 사이즈가 3이며 relu를 사용하는 Conv2D 레이어
  2. Max-Pooling 레이어
  3. 필터가 32개, 커널 사이즈가 3이며 relu를 사용하는 Conv2D 레이어
  4. Max-Pooling 레이어
  5. 1차원 변환
  6. 출력 노드가 256개이며 relu를 사용하는 fully-connected 레이어
  7. 출력값이 100개(100개의 클래스)이며 softmax를 사용하는 fully-connected 레이어
- Train
  - 최적화 함수 adam, 손실 함수 크로스엔트로피를 사용하여 모델 컴파일
  - Early Stopping 기능
  - 모델 피팅 (학습 횟수 5회)
  - 모델 평가

MNIST와 다르게 Max-Pooling 레이어와 Early Stopping 기능을 추가했습니다.

Max-Pooling 레이어를 통해 Conv2D 레이어로부터 얻은 정보를 가장 큰 값을 기준으로 압축하겠습니다.

<figure style = "width : 350px" class="align-center">
  <img src="{{ site.url }}{{ site.baseurl }}/assets/images/maxpooling.png" alt="">
  <figcaption>https://codetorial.net/tensorflow/convolutional_neural_network.html</figcaption>
</figure>

또한, 만약 loss가 2회 이상 증가할 경우 학습을 조기 종료하는 early stopping 기능을 도입하겠습니다.

### Sequential
### Functional
### Subclassing
